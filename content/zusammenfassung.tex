\section{Fazit}
Die Möglichkeiten Maschinen zu Überwachen und den aktuellen Maschinenzustand mittels Sensoren zu bestimmen werden immer größer. Nicht nur gegenwärtige Zustände, sondern auch vorhersagen von Zuständen sind mittlerweile möglich. Dadurch, dass schon kleinste Komponenten einer Maschine Sensordaten sammeln und diese zur Analyse bereitstellen, entsteht eine riesige Masse an Daten zur Weiterverarbeitung. Doch diese kontinuierlichen Datenflüsse stellen Lernalgorithmen an große Herausforderungen. 
Die Lernalgorithmen müssen unter harten Speicher- und Laufzeitanforderungen arbeiten und aus der Fülle an Daten die wichtigsten Informationen herausfiltern und diese auch möglichst noch für den Menschen verwendbar darstellen. 
Sensordaten fangen meist als einfache numerische Werte an, werden über die Anzahl an Parametern zu Vektoren zusammengefasst und ergeben über Vielfalt und Zeit meist sehr hochdimensionale Tensoren. In dieser Arbeit wurden Verfahren behandelt, welche diese Dimensionen für Lernalgorithmen durch Vorverarbeitung reduzieren.

Dabei werden \enquote{Feature Extraktions} Verfahren angewendet. Unter einem \enquote{Feature} versteht man ein Merkmal, wodurch sich Daten unterscheiden lassen. Verschiedene Ansätze versuchen die relevantesten Merkmale auszuwählen (Feature Selektion) oder durch Berechnungen neuer Merkmale zu extrahieren (Feature Extraktion). 

Einige dieser Ansätze bedienen sich bekannter Methoden, wodurch Datensätze mittels Transformationen parametrisiert werden und die Koeffizienten als Merkmale weiterverwendet werden können. Andere Ansätze Zerlegen die Daten durch additive oder multiplikative Methoden in verschiedene Informationshaltige Strukturen um aus diesen die Informationen besser extrahieren zu können. Ein Beispiel dafür die die Zerlegung in Trend und Saisonkomponenten.

Die Darstellung der Sensordaten als Kurven in einem Datenplot bietet auch visuelle Ansätze, indem die Daten Räumlich dargestellt werden und und dann durch Räumliche Zuordnungen klassifiziert und durch Merkmale unterschieden werden können. 

Andere Ansätze versuchen den Berechnungsaufwand so zu beschränken, dass zu Beginn die Berechnung unabhängig von der Größe des Datensatz ist und nur noch von der durch die Anzahl der Parameter bestimmten Dimension abhängt. Das anschließende Anwenden von \enquote{Feature Extraktion} liefert eine starke Laufzeiteinsparung.

Leider ist nie garantiert, dass durch die Extraktion ein Informationsverlust besteht und daher gibt es keine generelle Lösung für alle Datensätze. Die sogenannten Domänenexperten, die Personen welche sich Fachlich mit den Daten auskennen, sind vorerst Teil der Perfekten Analysekonfiguration. 
